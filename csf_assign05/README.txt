CONTRIBUTIONS: I worked on this milestone independently

Synchronization Report: 

In Milestone 2, I introduced concurrency to the server, enabling it to handle multiple clients simultaneously. This milestone presented challenges in ensuring proper synchronization of shared data structures—specifically the global map of tables and individual tables themselves—while preventing race conditions and deadlocks during transactions involving multiple tables. The global map, maintained in the Server class, maps table names (strings) to Table* pointers. Multiple client threads may attempt to look up or create tables concurrently. Without synchronization, these operations could lead to race conditions, memory corruption, or inconsistent views of the data. Each table maintains committed (m_final_data) and tentative (m_tentative_data) key-value pairs. Concurrent threads may attempt to read or modify the same table. Locking ensures that only one thread can reliably read or modify a table's state at any time. While transaction state in ClientConnection is local to a single client connection thread, transactions may involve locking multiple tables. Synchronization is required to ensure table locks are acquired and released correctly. However, transaction-specific data structures themselves do not require explicit synchronization as they are thread-local.

I employed several synchronization mechanisms to ensure correct behavior. In the Server class, a pthread_mutex_t protects the global std::map<std::string, Table*>. Before creating or looking up a table, the mutex is locked, ensuring safe updates and reads. Once the operation is complete, the mutex is unlocked to allow other threads access. Each Table has its own pthread_mutex_t. In autocommit mode, when no transaction is active, the server locks and unlocks the table for each operation using table->lock() and table->unlock(). In transaction mode, the server uses table->trylock() to acquire the lock without blocking. If trylock fails, a FailedTransaction exception is thrown, and the transaction is rolled back. This approach avoids indefinite blocking and reduces the risk of deadlocks.

To prevent deadlocks, I followed a well-defined strategy. Clients cannot start a new transaction inside an already active transaction, preventing scenarios where locks might be acquired in conflicting orders. During a transaction, if a table lock cannot be immediately acquired, the transaction fails. This eliminates the circular waiting condition that typically leads to deadlocks. In autocommit mode, each request touches at most one table. The server locks the table, performs the operation, commits changes if required, and immediately unlocks it. This fine-grained locking avoids holding multiple locks simultaneously for non-transactional operations. By using trylock for transactions and avoiding concurrent locks on multiple tables without a clear strategy, I eliminate potential deadlock scenarios. If a lock cannot be acquired, the transaction simply rolls back, releasing any locks it has already obtained.

My confidence in the system’s freedom from race conditions and deadlocks stems from several factors. I defined a clear locking protocol where the global table map lock is held during modifications or reads of the global map, and a table lock is held during reads or writes to that table. This ensures no unprotected access to shared data, eliminating race conditions. Autocommit operations never hold more than one lock at a time, preventing circular waiting. Transactions acquire locks in the order specified by requests but use trylock. If a lock is unavailable, the transaction aborts, preventing circular dependencies among threads. I extensively tested scenarios with multiple concurrent clients performing increments, sets, and gets, verifying both autocommit and transaction modes. The decision to immediately fail a transaction upon a failed trylock call ensures deadlock prevention by construction. Additionally, the simplicity of the concurrency model, which relies on a single global lock for the map, per-table locks for table data, and a no-wait strategy for transactions, reduces the risk of subtle bugs, ensuring that reasoning about deadlocks and race conditions remains straightforward and robust.






